{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 3a: Revision of block 3\n",
    "\n",
    "## Due: Friday the 23th of November 2017 23:59 p.m.\n",
    "\n",
    "*Please name your ipython notebook with the following naming convention: ASSIGNMENT_3_FIRSTNAME_LASTNAME.ipynb*\n",
    "\n",
    "*Please submit your assignment using [this google form](https://docs.google.com/forms/d/e/1FAIpQLSd0KC30woTId-SEhDUNEMJmHljNNksMsNmzqD6yCtH2pVuSmQ/viewform?usp=sf_link)*\n",
    "\n",
    "*If you have questions about this topic, please refer to the forum on the Canvas site.*\n",
    "\n",
    "\n",
    "In this block, we covered a lot of ground:\n",
    "\n",
    "* Chapter 11 - Functions and scope\n",
    "* Chapter 12 - Importing external modules \n",
    "* Chapter 13 - Working with Python scripts\n",
    "* Chapter 14 - Reading and writing text files\n",
    "* Chapter 15 - Off to analyzing text \n",
    "\n",
    "\n",
    "In this assignment, you will first complete a number of small exercises about each chapter to make sure you are familiar with the most important concepts. In the second part of the assignment, you will apply your newly acquired skills to write your very own text processing program (ASSIGNMENT-3b) :-). But don't worry, there will be instructions and hints along the way. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1: Practicing some core notions\n",
    "\n",
    "In the first part of this assignment, you will be revising some of the basic notions we covered in the previous chapters. Most of the exercises can be completed rather quickly. If you get stuck, you should be able to complete them by going bach to the chapters. The Purpose of this part is to make you gain some practice and confidence so you are all set and ready to move on to part 2 of the assignment - processing and analyzing some text! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions & scope"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Excercise 1:\n",
    "\n",
    "Define a function called `split_sort_text` which takes a string as input, splits it at space charaters and returns all the unique words in the string in alphabetical order. \n",
    "\n",
    "* Hint 1: There is a specific python container which does not allow for duplicates and simply removes them. Use this one. \n",
    "* Hint 2: There is a function which sorts items in an interable called 'sorted'. Look at the documentation to see how it is used. \n",
    "* Hint 3: Don't forget to write a docstring (here and in all future functions - we won't remind you every single time). \n",
    "* Hint 4: test your function\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Working with external modules"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2\n",
    "\n",
    "NLTK offers a way of using WordNet in python. Do some research (using google, because quite frankly, that's what we do very often) and see if you can find out how import it. WordNet is a computational lexicon which organizes words according to their senses (collected in synsets). See if you can print all the synsets (i.e. entries) of the word 'dog'. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Working with python scripts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise  3\n",
    "\n",
    "\n",
    "#### a.) Define a function called `count` which counts the words in a string. Do not use NLTK just yet. Find a way to test it.  \n",
    "\n",
    "* Hint 1: Write a helper-function called `preprocess` which preprocesses the string (split it, remove punctuation, return it in a container that you think works best for the next steps). \n",
    "\n",
    "* Hint 2: Remember that there are string methods which you can use to get rid of unwanted characters. Test the `preprocess` function using the string 'this is a (tricky) test'. \n",
    "\n",
    "* Tip 3: Remember how we used dictionaries to count words? If not, have a look at the containers chapter. \n",
    "\n",
    "* Hint 4: Test your function using an example string which will tell you whether it fullfils the requirements (remove punctuation, split, count). You will get a point for good testing.\n",
    "\n",
    "#### b.) Create a python script \n",
    "\n",
    "Use your editor to create a python script called `count_words.py`. Move your code into the python script and add a function call. Move your helper function to a seperate script which you call `utils.py`. Import your helper function into `word_counts.py`. Test whether everything works as expected by calling the scipt `word_counts.py` from the terminal. Include your tests in the `word_counts.py` script.\n",
    "\n",
    "**Please submit your scripts together with this notebook in a single folder and upload the entire folder to the google form**.\n",
    "\n",
    "Don't forget to add docstrings to your functions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Feel free to use this cell to try out your code. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dealing with text files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 4\n",
    "\n",
    "**Playing with lyrics**\n",
    "\n",
    "\n",
    "a.) Write a function called `load_text` which opens and reads a file and returns the text in the file. It should take a filepath as a parameter. Test it by loading this file: ../Data/lyrics/walrus.txt\n",
    "\n",
    "* Hint: remember it is best practice to use a content manager\n",
    "\n",
    "b.) Write a function called `replace_walrus`  which takes lyrics as input and replaces every instance of 'walrus' by 'hippo' (make sure to account for upper and lower case - it is fine to transform everything to lower case). The new version of the song should by written to a file called 'walrus_hippo.txt and stored in ../Data/lyrics. \n",
    "\n",
    "Don't forget to add docstrings to your functions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyzing text with nltk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 5\n",
    "\n",
    "**Building a simple NLP pipeline**\n",
    "\n",
    "For this exercise, you will need NLTK. Don't forget to import it. \n",
    "\n",
    "Write a function called `pos_tagging` which takes raw text as input and returns all the lemmas of nouns in it. To do this, make sure you follow the steps below:\n",
    "\n",
    "* Tokenize the text. \n",
    "\n",
    "* Perform part-of-speech tagging on the list of tokens. \n",
    "\n",
    "* Return the tagged text\n",
    "\n",
    "\n",
    "Then test your function using the text snipped below (`test_text`) as input.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_text = \"\"\"Two households, both alike in dignity,\n",
    "    In fair Verona, where we lay our scene,\n",
    "    From ancient grudge break to new mutiny,\n",
    "    Where civil blood makes civil hands unclean.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Python knowledge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 6\n",
    "\n",
    "6.a) How many for loops can you nest in one another? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer: infintely many"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6.b) What is the difference between the modes 'w' and 'a' when opening a file?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
